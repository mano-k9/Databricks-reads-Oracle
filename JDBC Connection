## Há um exemplo completo de conexão JDBC no Youtube:
## https://www.youtube.com/watch?v=3tAVXfIBqA8&t=93s

## use o Azure Key Vault para guardar o nome do usuário e a senha em segredo

## É preciso instalar o conector jdbc

## O código a seguir está em Python
## Você pode executa-lo em blocos no notebook do Azure Databricks
## Veja o mesmo código em SQL e Scala na página:
## https://learn.microsoft.com/en-us/azure/databricks/connect/external-systems/jdbc

username = dbutils.secrets.get(scope = "jdbc", key = "username")
password = dbutils.secrets.get(scope = "jdbc", key = "password")

## Lendo dados externos usando jdbc

employees_table = (spark.read
  .format("jdbc")
  .option("url", "<jdbc-url>")
  .option("dbtable", "<table-name>")
  .option("user", "<username>")
  .option("password", "<password>")
  .load()
)

employees_table.printSchema

display(employees_table.select("age", "salary").groupBy("age").avg("salary"))

## Gravando dados usando jdbc

(employees_table.write
  .format("jdbc")
  .option("url", "<jdbc-url>")
  .option("dbtable", "<new-table-name>")
  .option("user", "<username>")
  .option("password", "<password>")
  .save()
)

(employees_table.write
  .format("jdbc")
  .option("url", "<jdbc-url>")
  .option("dbtable", "<new-table-name>")
  .option("user", "<username>")
  .option("password", "<password>")
  .mode("append")
  .save()
)

(employees_table.write
  .format("jdbc")
  .option("url", "<jdbc-url>")
  .option("dbtable", "<new-table-name>")
  .option("user", "<username>")
  .option("password", "<password>")
  .mode("overwrite")
  .save()
)

